version: '3.9'

services:
  clickhouse-01:
    image: "clickhouse/clickhouse-server"
    user: "101:101"
    container_name: clickhouse-01
    hostname: clickhouse-01
    networks:
      sparknet:
        ipv4_address: 172.28.1.16
    volumes:
      - ./clickhouse/fs/volumes/clickhouse-01/etc/clickhouse-server/config.d/config.xml:/etc/clickhouse-server/config.d/config.xml
      - ./clickhouse/fs/volumes/clickhouse-01/etc/clickhouse-server/users.d/users.xml:/etc/clickhouse-server/users.d/users.xml
    ports:
      - "8123:8123"
      - "9000:9000"
    depends_on:
      - clickhouse-keeper-01
      - clickhouse-keeper-02
      - clickhouse-keeper-03

  clickhouse-02:
    image: "clickhouse/clickhouse-server"
    user: "101:101"
    container_name: clickhouse-02
    hostname: clickhouse-02
    networks:
      sparknet:
        ipv4_address: 172.28.1.17
    volumes:
      - ./clickhouse/fs/volumes/clickhouse-02/etc/clickhouse-server/config.d/config.xml:/etc/clickhouse-server/config.d/config.xml
      - ./clickhouse/fs/volumes/clickhouse-02/etc/clickhouse-server/users.d/users.xml:/etc/clickhouse-server/users.d/users.xml
    ports:
      - "8124:8123"
      - "9001:9000"
    depends_on:
      - clickhouse-keeper-01
      - clickhouse-keeper-02
      - clickhouse-keeper-03

  clickhouse-keeper-01:
    image: "clickhouse/clickhouse-keeper"
    user: "101:101"
    container_name: clickhouse-keeper-01
    hostname: clickhouse-keeper-01
    networks:
      sparknet:
        ipv4_address: 172.28.1.18
    volumes:
     - ./clickhouse/fs/volumes/clickhouse-keeper-01/etc/clickhouse-keeper/keeper_config.xml:/etc/clickhouse-keeper/keeper_config.xml
    ports:
        - "9181:9181"

  clickhouse-keeper-02:
    image: "clickhouse/clickhouse-keeper"
    user: "101:101"
    container_name: clickhouse-keeper-02
    hostname: clickhouse-keeper-02
    networks:
      sparknet:
        ipv4_address: 172.28.1.19
    volumes:
     - ./clickhouse/fs/volumes/clickhouse-keeper-02/etc/clickhouse-keeper/keeper_config.xml:/etc/clickhouse-keeper/keeper_config.xml
    ports:
        - "9182:9181"

  clickhouse-keeper-03:
    image: "clickhouse/clickhouse-keeper"
    user: "101:101"
    container_name: clickhouse-keeper-03
    hostname: clickhouse-keeper-03
    networks:
      sparknet:
        ipv4_address: 172.28.1.20
    volumes:
     - ./clickhouse/fs/volumes/clickhouse-keeper-03/etc/clickhouse-keeper/keeper_config.xml:/etc/clickhouse-keeper/keeper_config.xml
    ports:
        - "9183:9181"

  postgres:
    image: postgres
    container_name: postgres
    hostname: postgres
    environment:
      POSTGRES_USER: jupyter
      POSTGRES_PASSWORD: jupyter
    ports:
      - "5433:5432"
    command: postgres -c wal_level=logical
    volumes:
      - pg_data:/var/lib/postgresql/data
    restart: always
    healthcheck:
      test: ["CMD-SHELL", "pg_isready"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 3m
    networks:
      sparknet:
        ipv4_address: 172.28.1.15
    extra_hosts:
      - "master:172.28.1.2"
      - "worker1:172.28.1.3"
      - "worker2:172.28.1.4"
      - "history:172.28.1.5"

  metastore:
    image: postgres:11
    container_name: metastore
    hostname: metastore
    environment:
      POSTGRES_PASSWORD: jupyter
    ports:
      - "5432:5432"
    command: postgres -c wal_level=logical
    volumes:
      - metastore:/var/lib/postgresql/data
      - ./ddl/init.sql:/docker-entrypoint-initdb.d/init.sql
    restart: always
    healthcheck:
      test: ["CMD-SHELL", "pg_isready"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 3m
    networks:
      sparknet:
        ipv4_address: 172.28.1.1
    extra_hosts:
      - "master:172.28.1.2"
      - "worker1:172.28.1.3"
      - "worker2:172.28.1.4"
      - "history:172.28.1.5"

  master:
    image: hadoop-hive-spark-master
    container_name: master
    hostname: master
    depends_on:
      metastore:
        condition: service_healthy
    environment:
      SPARK_MASTER_HOST: 172.28.1.2
      SPARK_LOCAL_IP: 172.28.1.2
      SPARK_LOCAL_HOSTNAME: master
    ports:
      - "4040:4040"
      - "8020:8020"
      - "8080:8080"
      - "8088:8088"
      - "9870:9870"
      - "10000:10000"
    volumes:
      - namenode:/opt/hadoop/dfs/name
      - namesecondary:/opt/hadoop/dfs/namesecondary
    restart: always
    healthcheck:
      test: [ 'CMD', 'curl', '-f', 'http://127.0.0.1:9870']
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 5m
    networks:
      sparknet:
        ipv4_address: 172.28.1.2
    extra_hosts:
      - "metastore:172.28.1.1"
      - "worker1:172.28.1.3"
      - "worker2:172.28.1.4"
      - "history:172.28.1.5"

  worker1:
    image: hadoop-hive-spark-worker
    container_name: worker1
    hostname: worker1
    depends_on:
      master:
        condition: service_healthy
    environment:
      SPARK_MASTER_HOST: 172.28.1.2
      SPARK_LOCAL_IP: 172.28.1.3
      SPARK_LOCAL_HOSTNAME: worker1
    ports:
      - "8042:8042"
      - "8081:8081"
      - "9864:9864"
    volumes:
      - datanode1:/opt/hadoop/dfs/data
    restart: always
    healthcheck:
      test: [ 'CMD', 'curl', '-f', 'http://127.0.0.1:9864' ]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 5m
    networks:
      sparknet:
        ipv4_address: 172.28.1.3
    extra_hosts:
      - "metastore:172.28.1.1"
      - "master:172.28.1.2"
      - "worker2:172.28.1.4"
      - "history:172.28.1.5"

  worker2:
    image: hadoop-hive-spark-worker
    container_name: worker2
    hostname: worker2
    depends_on:
      - master
    environment:
      SPARK_MASTER_HOST: 172.28.1.2
      SPARK_LOCAL_IP: 172.28.1.4
      SPARK_LOCAL_HOSTNAME: worker2
    ports:
      - "8043:8042"
      - "8082:8081"
      - "9865:9864"
    volumes:
      - datanode2:/opt/hadoop/dfs/data
    restart: always
    healthcheck:
      test: [ 'CMD', 'curl', '-f', 'http://127.0.0.1:9864' ]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 5m
    networks:
      sparknet:
        ipv4_address: 172.28.1.4
    extra_hosts:
      - "metastore:172.28.1.1"
      - "master:172.28.1.2"
      - "worker1:172.28.1.3"
      - "history:172.28.1.5"

  history:
    image: hadoop-hive-spark-history
    container_name: history
    hostname: history
    depends_on:
      master:
        condition: service_healthy
      worker1:
        condition: service_healthy
      worker2:
        condition: service_healthy
    environment:
      SPARK_MASTER_HOST: 172.28.1.2
      SPARK_LOCAL_IP: 172.28.1.5
      SPARK_LOCAL_HOSTNAME: history
    ports:
      - "18080:18080"
      - "19888:19888"
    restart: always
    healthcheck:
      test: [ 'CMD', 'curl', '-f', 'http://127.0.0.1:19888' ]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 5m
    networks:
      sparknet:
        ipv4_address: 172.28.1.5
    extra_hosts:
      - "metastore:172.28.1.1"
      - "master:172.28.1.2"
      - "worker1:172.28.1.3"
      - "worker2:172.28.1.4"

  jupyter:
    image: samrez84/hadoop-spark-lab-jupyter
    container_name: jupyter
    hostname: jupyter
    environment:
      SPARK_MASTER_HOST: 172.28.1.2
      SPARK_LOCAL_IP: 172.28.1.6
      SPARK_LOCAL_HOSTNAME: jupyter
    depends_on:
      master:
        condition: service_healthy
      worker1:
        condition: service_healthy
      worker2:
        condition: service_healthy
    ports:
      - "8888:8888"
    volumes:
      - ./jupyter:/home/jupyter
    restart: always
    healthcheck:
      test: [ 'CMD', 'curl', '-f', 'http://127.0.0.1:8888' ]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      sparknet:
        ipv4_address: 172.28.1.6
    extra_hosts:
      - "metastore:172.28.1.1"
      - "master:172.28.1.2"
      - "worker1:172.28.1.3"
      - "worker2:172.28.1.4"
      - "history:172.28.1.5"

  zookeeper:
    image: confluentinc/cp-zookeeper:7.3.1
    hostname: zookeeper
    container_name: zookeeper
    ports:
      - '2181:2181'
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    volumes:
      - zookeeper-data:/var/lib/zookeeper/data
      - zookeeper-logs:/var/lib/zookeeper/log
    healthcheck:
      test: echo srvr | nc zookeeper 2181 || exit 1
      start_period: 10s
      retries: 20
      interval: 10s
    networks:
      sparknet:
        ipv4_address: 172.28.1.7

  broker1:
    image: confluentinc/cp-kafka:7.3.1
    hostname: broker1
    container_name: broker1
    depends_on:
      zookeeper:
        condition: service_healthy
    ports:
      - '29092:29092'
      - '9092:9092'
      - '9101:9101'
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://broker1:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
      KAFKA_JMX_PORT: 9101
      KAFKA_JMX_HOSTNAME: localhost
    volumes:
      - broker1-data:/var/lib/kafka/data
      - broker1-logs:/var/log/kafka
    healthcheck:
      test: nc -z localhost 9092 || exit -1
      start_period: 15s
      interval: 5s
      timeout: 10s
      retries: 10
    networks:
      sparknet:
        ipv4_address: 172.28.1.8
  broker2:
    image: confluentinc/cp-kafka:7.3.1
    hostname: broker2
    container_name: broker2
    depends_on:
      zookeeper:
        condition: service_healthy
    ports:
      - '29093:29092'
      - '9093:9093'
      - '9102:9102'
    environment:
      KAFKA_BROKER_ID: 2
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://broker2:29092,PLAINTEXT_HOST://localhost:9093
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
      KAFKA_JMX_PORT: 9102
      KAFKA_JMX_HOSTNAME: localhost
    volumes:
      - broker2-data:/var/lib/kafka/data
      - broker2-logs:/var/log/kafka
    healthcheck:
      test: nc -z localhost 9093 || exit -1
      start_period: 15s
      interval: 5s
      timeout: 10s
      retries: 10
    networks:
      sparknet:
        ipv4_address: 172.28.1.9

  broker3:
    image: confluentinc/cp-kafka:7.3.1
    hostname: broker3
    container_name: broker3
    depends_on:
      zookeeper:
        condition: service_healthy
    ports:
      - '29094:29092'
      - '9094:9094'
      - '9103:9103'
    environment:
      KAFKA_BROKER_ID: 3
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://broker3:29092,PLAINTEXT_HOST://localhost:9094
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
      KAFKA_JMX_PORT: 9103
      KAFKA_JMX_HOSTNAME: localhost
    volumes:
      - broker3-data:/var/lib/kafka/data
      - broker3-logs:/var/log/kafka
    healthcheck:
      test: nc -z localhost 9094 || exit -1
      start_period: 15s
      interval: 5s
      timeout: 10s
      retries: 10
    networks:
      sparknet:
        ipv4_address: 172.28.1.10

  debezium:
    image: debezium/connect:latest
    restart: always
    container_name: debezium
    hostname: debezium
    depends_on:
      metastore:
        condition: service_healthy
      broker1:
        condition: service_healthy
      broker2:
        condition: service_healthy
      broker3:
        condition: service_healthy
    ports:
      - '28083:8083'
    environment:
      BOOTSTRAP_SERVERS: broker1:29092,broker2:29092,broker3:29092
      GROUP_ID: 1
      CONFIG_STORAGE_TOPIC: connect_configs
      STATUS_STORAGE_TOPIC: connect_statuses
      OFFSET_STORAGE_TOPIC: connect_offsets
      KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      ENABLE_DEBEZIUM_SCRIPTING: 'true'
    healthcheck:
      test:
        [
          'CMD',
          'curl',
          '--silent',
          '--fail',
          '-X',
          'GET',
          'http://localhost:8083/connectors',
        ]
      start_period: 5m
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      sparknet:
        ipv4_address: 172.28.1.11

  schema-registry:
    image: confluentinc/cp-schema-registry:7.3.1
    hostname: schema-registry
    container_name: schema-registry
    restart: always
    depends_on:
      broker1:
        condition: service_healthy
      broker2:
        condition: service_healthy
      broker3:
        condition: service_healthy
    ports:
      - '28081:8081'
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: 'broker1:29092,broker2:29092,broker3:29092'
      SCHEMA_REGISTRY_LISTENERS: http://0.0.0.0:8081

    healthcheck:
      start_period: 5m
      interval: 10s
      retries: 20
      test: curl --user superUser:superUser --fail --silent --insecure http://localhost:8081/subjects --output /dev/null || exit 1
    networks:
      sparknet:
        ipv4_address: 172.28.1.12

  rest-proxy:
    image: confluentinc/cp-kafka-rest:7.3.1
    depends_on:
      broker1:
        condition: service_healthy
      broker2:
        condition: service_healthy
      broker3:
        condition: service_healthy
    ports:
      - '28082:8082'
    hostname: rest-proxy
    container_name: rest-proxy
    restart: always
    environment:
      KAFKA_REST_HOST_NAME: rest-proxy
      KAFKA_REST_BOOTSTRAP_SERVERS: 'broker1:29092,broker2:29092,broker3:29092'
      KAFKA_REST_LISTENERS: 'http://0.0.0.0:8082'
    networks:
      sparknet:
        ipv4_address: 172.28.1.13

  debezium-ui:
    image: debezium/debezium-ui:latest
    restart: always
    container_name: debezium-ui
    hostname: debezium-ui
    depends_on:
      debezium:
        condition: service_healthy
    ports:
      - '28080:8080'
    environment:
      KAFKA_CONNECT_URIS: http://debezium:8083
    networks:
      sparknet:
        ipv4_address: 172.28.1.14

  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    ports:
      - "10001:10000"
    networks:
      sparknet:
    depends_on:
      broker1:
        condition: service_healthy
      broker2:
        condition: service_healthy
      broker3:
        condition: service_healthy
    environment:
      DYNAMIC_CONFIG_ENABLED: 'true'
    volumes:
      - ./kui/config.yml:/etc/kafkaui/dynamic_config.yaml

volumes:
  namenode:
  namesecondary:
  datanode1:
  datanode2:
  metastore:
  pg_data:
  zookeeper-data:
  zookeeper-logs:
  broker1-data:
  broker1-logs:
  broker2-data:
  broker2-logs:
  broker3-data:
  broker3-logs:

networks:
  sparknet:
    external: true