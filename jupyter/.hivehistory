col4 int)
row format delimited
fields terminated by ','
collection items terminated by ':'
lines terminated by '\n'
stored as textfile;
create table if not exists tbl2(
col1 string,
col2 array<string>,
col3 string,
col4 int);
set hive.metastore.warehouse.dir;
create table if not exists tbl1(
    > col1 string,
    > col2 array<string>,
    > col3 string,
use db1;
show databases;
use d1;
show tables;
create external table tbl12(col1 string, col2 array<string>, col3 string, col4 int) row format delimited fields terminated by ',' collection items terminated by ':' lines terminated by '\n' stored as textfile;
load data local inpath '/home/jupyter/table1.txt' into table tbl12;
select * from tbl12;
drop table tbl12;
select * from tbl12;
create table tbl_retail (customer_id string, customer_name string, order_date date, ship_date date, courier string, received_date date, status bool, reason_of_return string) row format delimited fields terminated by ',' collection items terminated by ':' lines terminated by '\n' stored as textfile;
create table tbl_retail (customer_id string, customer_name string, order_date date, ship_date date, courier string, received_date date, status boolean, reason_of_return string) row format delimited fields terminated by ',' collection items terminated by ':' lines terminated by '\n' stored as textfile;
load data local inpath '/user/jupyter/assignment_create_table_2018.txt' into table tbl_retail;
load data local inpath '/home/jupyter/assignment_create_table_2018.txt' into table tbl_retail;
select * from tbl_retail;
show databases;
use d1;
show tables;
dsecribe database d1;
describe database da1;
describe database d1;
describe database d2;
describe extended database d2;
describe database extended d2;
describe database formatted d2;
describe database d3;
describe database extended d3;
shao databases;
shaw databases;
show databases;
use d1;
show tables;
describe extended tbl1;
describe formatted tbl1;
describe formatted tbl3;
set hive.cli.print.header;
set hive.cli.print.header=true;
set hive.cli.print.header;
show tables;
select * from tbl_employee;
select * from tbl_emp;
select * from tab1;
describe formatted tab1;
show atbles;
show tables;
create table tab(col1 int, col2 string, col3 string) stored as textfile;
insert into table tab select col1, col2, col3 from tbl_emp;
select * from tab;
insert into table tab select col1, col2, col3 from tbl_emp;
select * from tab;
insert overwrite table tab select col1, col2, col3 from tbl_emp;
select * from tab;
insert overwrite table tab select col1, col2, col3 from tbl_emp where col3 = 'Developer';
select * from tab;
show tables;
select * from tab_name;
select * from tab1;
drop table tab1;
show tables;
select * from tbl_retail;
from tbl_emp insert overwrite \
from tbl_emp \
insert overwrite tbl_developer select col1, col2, col3 where col3 = 'Developer' \
insert overwrite tbl_manager select col1, col2, col3 where col3 = 'Manager';
describe extended tbl_emp;
use d1;
from tbl_emp \
insert overwrite tbl_developer select col1, col2, col3 where col3 = 'Developer' \
insert overwrite tbl_manager select col1, col2, col3 where col3 = 'Manager';
select surrent_database();
select current_database();;
use default;
show tables;
use d1;
insert overwrite tbl_developer select col1, col2, col3 where col3 = 'Developer' \
;
show tables;
from tbl_emp \
use d1;
shpw tables;
show tables;
set hive.cli.show.header;
set hive.metastore.warehouse.dir;
desc tab;
alter table tab change col1 col1 int after col4;
alter table tab change col1 col1 int after col3;
alter table tab change column col2 new_col2 string;
desc tab;
alter table tab rename to tab1;
desc tab1;
alter table tab1 change col3 col3 string after col4;
desc tab1;
alter table tab1 change col1 col1 int after col3;
alter table tab1 change col1 col1 int after col5;
alter table tab1 change col1 col1 int after col4;
alter table tab1 change col1 col1 int after new_col2;
desc tab1;
select * from tab1;
alter table tab1 replace columns(id int, name string);
desc tab1;
select * from tab1;
desc formatted tab1;
alter table tab1 set tblproperties{"auto.purge"="true"}
;
alter table tab1 set tblproperties("auto.purge"="true");
desc formatted tab1;
alter table tab1 set fileformat avro;
desc formatted tab1;
create table tbl_order(col1 string, col2 int) row format delimited fields terminated by ',' stored as textfile;
load data local inpath '/user/jupyter/order.txt' insert into table tbl_order;
load data local inpath '/user/jupyter/order.txt' into table tbl_order;
load data local inpath '/home/jupyter/order.txt' into table tbl_order;
select * from tbl_order;
select col2 from tbl_order order by col2;
select col2 from tbl_order order by col2 limit 5;
select col2 from tbl_order sort by col2;
select col2 from tbl_order distribute by col2;
select col2 from tbl_order distribute by col2 sort by col2;
select col2 from tbl_order cluster by col2;
select unix_timestamp('2017-04-26 00:00:00');
select from_unixtime(1234145);
use d1;
show tables;
select * from tbl1;
set hive.cli.show.headrs;
set hive.cli.show.headr;
set hive.cli.print.headr;
set hive.cli.print.headrs;
set hive.cli.print.header;
set hive.cli.print.header=true;
set hive.cli.print.header;
select * from tbl1;
select concat(col1, '-', col3) from tbl1;
select length(col3) from tbl1;
select lpad(col3, 15, '-') from tbl1;
select cpad(col3, 15, '-') from tbl1;
select rpad(col3, 15, '-') from tbl1;
select mpad(col3, 15, '-') from tbl1;
select ltrim('       sam');
select rtirm(ltrim('       sam             '));
select rtrim(ltrim('       sam             '));
select repeat(col3, 3) from tbl1;
set hive.exec.scratchdir;
create table tbl_book(author_name string, book_name array<string>) row format delimited fields terminated by ',' collection items terminated by ':' lines terminated by '\n' stored as textfile;
drop table tbl_book;
use d1;
create table tbl_book(author_name string, book_name array<string>) row format delimited fields terminated by ',' collection items terminated by ':' lines terminated by '\n' stored as textfile;
load data local inpath '/home/jupyter/explode_new_data.txt' into table tbl_book;
select * from tbl_book;
select author_name, book_name from tbl_book lateral view explode(book_name) dummy as dummy_books_name;
use d1;
show tables;
select * from tbl3;
select
    e.col1, e.col2, e.col3,
    d.dep_id, d.dep_name
from tbl_emp e
join tbl_dep d on e.col6 = d.dep_id;
use d1;
select
    e.col1, e.col2, e.col3,
    d.dep_id, d.dep_name
from tbl_emp e
join tbl_dep d on e.col6 = d.dep_id;
select
    e.col1, e.col2, e.col3,
    d.dep_id, d.dep_name
from tbl_emp e
left outer join tbl_dep d on e.col6 = d.dep_id;
create table tbl_third(col1 int, col2 string) row format delimited stored as textfile;
insert into table tbl_third values(10, 1st department), (20, 2nd department), (30, 3rd department), (40, 4th department);
insert into tbl_third values(10, 1st department), (20, 2nd department), (30, 3rd department), (40, 4th department);
insert into table tbl_third values (10, 1st department);
insert into tbl_third values(10, '1st department'), (20, '2nd department'), (30, '3rd department'), (40, '4th department');
select * from tbl_third;
select
    e.col1, e.col2,
    d.dep_name, d.salary,
    t.col2
from tbl_emp e 
    join tbl_dep d 
        on e.col6 = d.dep_id
    join tbl_third t 
        on t.col1 = d.dep_id;
select * from tbl_emp limit 10;
set hive.cli.print.header=true;
select * from tbl_emp limit 10;
select * from tbl_dep limit 10;
select /*+STREAMTABLE {tbl_emp} */
    e.col1, e.col2,
    d.dep_name, d.salary,
    t.col2
from tbl_emp e
    join tbl_dep d
        on e.col6 = d.dep_id
    join tbl_third t
        on t.col1 = d.dep_id;
select /*+STREAMTABLE {tbl_emp} */
    e.col1, e.col2,
    d.dep_name, d.salary,
    t.col2
from tbl_emp e
    join tbl_dep d
        on e.col6 = d.dep_id
    join tbl_third t
        on t.col1 = d.dep_id;
select /*+STREAMTABLE (tbl_emp) */
    e.col1, e.col2,
    d.dep_name, d.salary,
    t.col2
from tbl_emp e
    join tbl_dep d
        on e.col6 = d.dep_id
    join tbl_third t
        on t.col1 = d.dep_id; 
select /*+STREAMTABLE (tbl_emp) */
    e.col1, e.col2,
    d.dep_name, d.salary,
    t.col2
from tbl_emp e
    join tbl_dep d
        on e.col7 = d.salary
    join tbl_third t
create view vw_emp_1 as select * from tbl_emp;
select current_database();
use d1;
create view vw_emp_1 as select * from tbl_emp;
show views;
select * from vw_emp_1;
create view vw_emp_2 as select col1,col2,col3 from tbl_emp;
select * from vw_emp_2;
set hive.cli.print.header=true;
select * from vw_emp_2;
create view if not exists vw_emp_3 as select col1 as id, col2 as name from tbl_emp;
select * from vw_emp_3;
create view vw_emp_4 
as 
select
    e.col1, e.col2, e.col3,
    d.dep_id, d.dep_name
from tbl_emp e
join tbl_dep d on e.col6 = d.dep_id;
select * from vw_emp_4;
alter view vw_emp_1 as select col1 from tbl_emp;
select * from vw_emp_1;
alter view vw_emp_1 rename to vw_emp_new;
desc vw_emp_new;
show tables;
select * from tbl_dep limit 10;
select * from tbl_ass3;
select * from tbl_ass2;
create table tbl_indx(col1 int, col2 string, col3 string, col4 int) row format delited fields terminated by ',' stored as textfile;
create table tbl_indx(col1 int, col2 string, col3 string, col4 int) row format delimited fields terminated by ',' stored as textfile;
desc tbl_indx;
load data local inpath '/home/jupyter/index.txt' into table tbl_indx;
select count(*) from tbl_indx;
select * from tbl_indx limit 5;
create index on table tbl_indx (col3) as 'COMPACT' with deffered rebuild;
create index i1 on table tbl_indx (col3) as 'COMPACT' with deffered rebuild;
create index i1 on table tbl_indx (col3) as 'COMPACT' wi
;
set hive.version;
create index
;
create index i1 on table tbl_indx (col3) as 'COMPACT' with deffered rebuild;
show tables;
create index indx1 on table tbl_indx(col3) as 'COMPACT' with deffered rebuild;
use d1;
show tables;
show indexes;
create index indx1 on table tbl_indx(col3) as 'COMPACT' with deffered rebuild;
set dfs.block.size;
set parquet.block.size;
set hive.default.fileformat;
create table tbl_paral(col1 int, col2 string) row format delimited fields terminated by ',' lines terminated by '\n' stored as;
use d1;
create table tbl_paral(col1 int, col2 string) row format delimited fields terminated by ',' lines terminated by '\n' stored as textfile;
load data local inpath '/home/jupyter/parallel.txt' into table tbl_paral;
select * from tbl_paral;
set hive.exec.parallel;
set hive.exec.parallel=true;
set hive.exec.parallel;
select * from tbl_indx;
select a.col1, a.col2, b.col2 from (select * from tbl_indx where col4 = 2012) a join (select * from tbl_paral where col2 = 'e') b on a.col1=b.col1;
set hive.exec.parallel=false;
select a.col1, a.col2, b.col2 from (select * from tbl_indx where col4 = 2012) a join (select * from tbl_paral where col2 = 'e') b on a.col1=b.col1;
set hive.exec.parallel=true;
select a.col1, a.col2, b.col2 from (select * from tbl_indx where col4 = 2012) a join (select * from tbl_paral where col2 = 'e') b on a.col1=b.col1;
desc tbl_emp;
source /home/jupyter/hive_files/script.hql;
!pwd
;
!echo "hello";
!ls c*;
!pwd
;
!cd hive_files;
!dfs -ls /
;
dfs -ls;
dfs -ls /;
set deptno=40;
set deptno;
select * from tbl_emp where col6 = ${hiveconf:d1};
select * from tbl_emp where col6 = $(hiveconf:d1);
select * from tbl_emp where col6 = $(hiveconf:deptno);
use d1;
select * from tbl_emp where col6 = $(hiveconf:deptno);
show tables;
select * from tbl_emp where col6 = ${hiveconf:deptno};
select * from tbl_emp where col6 = ${hiveconf:d1};
set deptno=40;
set deptno;
set hiveconf:d1=20;
set hiveconf:deptno;
set hiveconf:d1;
select * from tbl_emp where col6 = ${hiveconf:d1};
select * from tbl_emp where col6 = ${hiveconf:deptno};
set hivevar: deptnumber = 10;
select * from tbl_emp where col6 = ${deptnumber};
set hivevar: deptnumber;
select * from tbl_emp where col6 = ${deptnumber};
select * from tbl_emp where col6 = ${hivevar:deptnumber};
select * from tbl_emp where col6 limit 10;
select * from tbl_emp where col6=10 limit 10;
set hivevar: deptnumber;
set deptnumber;
set hivevar: deptnumber;
set hiveconf:d1=20;
select * from tbl_emp where col6=${hiveconf:d1};
set hivevar:deptnumber=10;
select * from tbl_emp where col6 = ${deptnumber};
set hivevar:name = col6;
set hivevar:name = col2;
select col1, ${name} from tbl_emp where col6 = ${hiveconf:deptno};
set tbl = tbl9;
set new_tbl = ${hiveconf:tbl};
set new_tbl;
use d1;
!pwd
;
add jar hive_files/hivexmlserde-1.0.0.0.jar;
create table tbl_xml(title string, author string, country string, company string, price float, year int) row format serde 'com.ibm.spss.hive.serde2.xml.xmlSerde' with serdeproperties ( 
"column.xpath.title"="/book/title/text()"
"column.xpath.author"="/book/author/text()"
"column.xpath.country"="/book/company/text()"
"column.xpath.company"="/book/company/text()"
"column.xpath.price"="/book/price/
;
create table tbl_xml(title string, author string, country string, company string, price float, year int) row format serde 'com.ibm.spss.hive.serde2.xml.xmlSerde' with serdeproperties ("column.xpath.title"="/book/title/text()","column.xpath.author"="/book/author/text()","column.xpath.country"="/book/company/text()","column.xpath.company"="/book/company/text()","column.xpath.price"="/book/price/text()","column.xpath.year"="/book/year/text()" stored as inputformat 'com.ibm.spss.hive.serde2.xml.xmlInputFormat' outputformat 'org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat' tblproperties ("xmlinput.start"="<BOOK", "xmlinput.end"="</BOOK");
create table tbl_xml(
title string, 
author string, 
country string, 
company string, 
price float, 
year int) 
row format serde 'com.ibm.spss.hive.serde2.xml.xmlSerde' 
with serdeproperties (
"column.xpath.title"="/book/title/text()",
"column.xpath.author"="/book/author/text()",
"column.xpath.country"="/book/company/text()",
"column.xpath.company"="/book/company/text()",
"column.xpath.price"="/book/price/text()",
"column.xpath.year"="/book/year/text()")
stored as 
inputformat 'com.ibm.spss.hive.serde2.xml.xmlInputFormat' 
outputformat 'org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat' 
tblproperties ("xmlinput.start"="<BOOK", "xmlinput.end"="</BOOK");
create table tbl_xml(
title string, 
author string, 
country string, 
company string, 
price float, 
year int) 
row format serde 'com.ibm.spss.hive.serde2.xml.XmlSerde' 
with serdeproperties (
"column.xpath.title"="/book/title/text()",
"column.xpath.author"="/book/author/text()",
"column.xpath.country"="/book/company/text()",
"column.xpath.company"="/book/company/text()",
"column.xpath.price"="/book/price/text()",
"column.xpath.year"="/book/year/text()")
stored as 
inputformat 'com.ibm.spss.hive.serde2.xml.XmlInputFormat' 
outputformat 'org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat' 
tblproperties ("xmlinput.start"="<BOOK", "xmlinput.end"="</BOOK");
create table tbl_xml(
title string, 
author string, 
country string, 
company string, 
price float, 
year int) 
row format serde 'com.ibm.spss.hive.serde2.xml.xmlSerde' 
with serdeproperties (
"column.xpath.title"="/book/title/text()",
"column.xpath.author"="/book/author/text()",
"column.xpath.country"="/book/company/text()",
"column.xpath.company"="/book/company/text()",
"column.xpath.price"="/book/price/text()",
"column.xpath.year"="/book/year/text()")
stored as 
inputformat 'com.ibm.spss.hive.serde2.xml.XmlInputFormat' 
outputformat 'org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat' 
tblproperties ("xmlinput.start"="<BOOK", "xmlinput.end"="</BOOK");
create table tbl_xml(
title string, 
author string, 
country string, 
company string, 
price float, 
year int) 
row format serde 'com.ibm.spss.hive.serde2.xml.XmlSerde' 
with serdeproperties (
"column.xpath.title"="/book/title/text()",
"column.xpath.author"="/book/author/text()",
"column.xpath.country"="/book/company/text()",
"column.xpath.company"="/book/company/text()",
"column.xpath.price"="/book/price/text()",
"column.xpath.year"="/book/year/text()")
stored as 
inputformat 'com.ibm.spss.hive.serde2.xml.XmlInputFormat' 
outputformat 'org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat' 
tblproperties ("xmlinput.start"="<BOOK", "xmlinput.end"="</BOOK");
ADD JAR /home/jupyter/hive_files/hivexmlserde-1.0.5.3.jar;
create table tbl_xml(
title string, 
author string, 
country string, 
company string, 
price float, 
year int) 
row format serde 'com.ibm.spss.hive.serde2.xml.XmlSerde' 
with serdeproperties (
"column.xpath.title"="/book/title/text()",
"column.xpath.author"="/book/author/text()",
"column.xpath.country"="/book/company/text()",
"column.xpath.company"="/book/company/text()",
"column.xpath.price"="/book/price/text()",
"column.xpath.year"="/book/year/text()")
stored as 
inputformat 'com.ibm.spss.hive.serde2.xml.XmlInputFormat' 
outputformat 'org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat' 
tblproperties ("xmlinput.start"="<BOOK", "xmlinput.end"="</BOOK");
use d1;
create table tbl_xml(
title string, 
author string, 
country string, 
company string, 
price float, 
year int) 
row format serde 'com.ibm.spss.hive.serde2.xml.XmlSerde' 
with serdeproperties (
"column.xpath.title"="/book/title/text()",
"column.xpath.author"="/book/author/text()",
"column.xpath.country"="/book/company/text()",
"column.xpath.company"="/book/company/text()",
"column.xpath.price"="/book/price/text()",
"column.xpath.year"="/book/year/text()")
stored as 
inputformat 'com.ibm.spss.hive.serde2.xml.XmlInputFormat' 
outputformat 'org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat' 
tblproperties ("xmlinput.start"="<BOOK", "xmlinput.end"="</BOOK");
create table tbl_xml(
title string, 
author string, 
country string, 
company string, 
price float, 
year int) 
row format serde 'com.ibm.spss.hive.serde2.xml.xmlSerde' 
with serdeproperties (
"column.xpath.title"="/book/title/text()",
"column.xpath.author"="/book/author/text()",
"column.xpath.country"="/book/company/text()",
"column.xpath.company"="/book/company/text()",
"column.xpath.price"="/book/price/text()",
"column.xpath.year"="/book/year/text()")
stored as 
inputformat 'com.ibm.spss.hive.serde2.xml.XmlInputFormat' 
outputformat 'org.apache.hadoop.hive.ql.io.IgnoreKeyTextOutputFormat' 
tblproperties ("xmlinput.start"="<BOOK", "xmlinput.end"="</BOOK");
